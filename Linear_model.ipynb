{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e1bc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, fixed, widgets\n",
    "\n",
    "np.random.seed(2023)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9cdb908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:\n",
    "  '''\n",
    "    Simple linear model with a single output (y) given the covariates x_1...x_M of the form:\n",
    "    y = w_1 * x_1 + ... + w_M * x_M + b\n",
    "    where M = number of features, w are the weights, and b is the bias.\n",
    "  '''\n",
    "  def __init__(self):\n",
    "    self.w=None\n",
    "    self.b=None\n",
    "  def evaluate_proposal(self,data,theta):\n",
    "    '''\n",
    "      Function to load a given proposal distribution (theta) and return the model prediction\n",
    "      data: DataFrame with columns x_1, x_2, ..., x_M\n",
    "      theta: List of model parameters [w_1, w_2, ..., w_M, b]\n",
    "    '''\n",
    "    self.encode(theta)\n",
    "    return self.predict(data)\n",
    "  def predict(self,x_in):\n",
    "    '''\n",
    "      Function to output y given the input data and model parameters\n",
    "      data: DataFrame with columns x_1, x_2, ..., x_M\n",
    "    '''\n",
    "    y_out=x_in.dot(self.w) + self.b\n",
    "    return y_out\n",
    "  def encode(self,theta):\n",
    "    '''\n",
    "      Helper function to encode the model parameters (theta) into the model as w and b\n",
    "      theta: List of model parameters [w_1, w_2, ..., w_M, b]\n",
    "    '''\n",
    "    self.w=theta[:-1]\n",
    "    self.b=theta[-1]\n",
    "      \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542e56c",
   "metadata": {
    "vscode": {
     "languageId": "yaml"
    }
   },
   "outputs": [],
   "source": [
    "#  defining the likelihood and prior distributions\n",
    "def likelihood(self,theta,tausq,test=False):\n",
    "  '''\n",
    "    Function to compute the likelihood of the data given the model parameters\n",
    "    theta: List of model parameters [w_1, w_2, ..., w_M, b]\n",
    "    data: DataFrame with columns x_1, x_2, ..., x_M and y\n",
    "    tausq: Variance of the noise in the data\n",
    "    test: If True, return only the prediction without computing the likelihood\n",
    "  '''\n",
    "  if test:\n",
    "    x_data=self.x_test\n",
    "    y_data=self.y_test\n",
    "  else:\n",
    "    x_data=self.x_data\n",
    "    y_data=self.y_data\n",
    "  # making  prediction prediction using parameters theta\n",
    "  y_pred=self.model.evaluate_proposal(theta,x_data)\n",
    "  model_simulation=y_pred+np.np.random.normal(0.tausq,size=y_pred.shape)\n",
    "  # checking the rmse for debugging\n",
    "  rmse=self.rmse(y_pred,y_data)\n",
    "  # computing the likelihood\n",
    "  log_likelihood=np.sum(-0.5*np.log(2*np.pi*tausq)-0.5*np.square(y_data-y_pred)/tausq)\n",
    "  return [log_likelihood,y_pred,model_simulation,rmse]\n",
    "#  defining the prior distribution\n",
    "def prior(self,sigma_sqr,nu_1,nu_2,theta,tausq):\n",
    "  '''\n",
    "    Function to compute the prior distribution of the model parameters\n",
    "    sigma_sqr: Variance of the prior distribution\n",
    "    nu_1: Degrees of freedom for the prior distribution\n",
    "    nu_2: Scale parameter for the prior distribution\n",
    "    theta: List of model parameters [w_1, w_2, ..., w_M, b]\n",
    "    tausq: Variance of the noise in the data\n",
    "    where tausq ,nu_1, nu_2 are hyperparameters user need to give\n",
    "    Output: log prior distribution\n",
    "  '''\n",
    "  n_params=self.theta_size # number of parameters in the model\n",
    "  part_1=-1 * (n_params / 2) * np.log(sigma_sqr)\n",
    "  part_2=1/(2 * sigma_sqr) * np.sum(np.square(theta))\n",
    "  inv_gamma_part=- (1 + nu_1) * np.log(tausq) - (nu_2 / tausq)\n",
    "  return part_1 - part_2 + inv_gamma_part\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6520ae28",
   "metadata": {},
   "source": [
    "Appling MCMC Sampling the core heart like gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "657154b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MCMC_sampler(self):\n",
    "  post_theta=np.ones((self.n_samples, self.theta_size))\n",
    "  post_tau=np.ones((self.n_samples,1))\n",
    "  post_eta=np.ones((self.n_samples,1))\n",
    "  y_pred=np.zeros((self.n_samples,self.x_data.shape[0]))\n",
    "  #  stroring the simulated values f(x) + error all over samples\n",
    "  y_sim=np.zeros((self.n_samples,self.x_data.shape[0]))\n",
    "  #  storing the rmse of each sample\n",
    "  rmse=np.zeros(self.n_samples)\n",
    "  # in case of testing \n",
    "  y_test_pred=np.ones((self.n_samples,self.x_test.shape[0]))\n",
    "  y_sim_test=np.ones((self.n_samples,self.x_test.shape[0]))\n",
    "  rmse_test=np.zeros(self.n_samples)\n",
    "  #  initial values for the model parameters\n",
    "  theta=np.random.randn(self.theta_size)\n",
    "  #  making the prediction first time'\n",
    "  y_pred[0,]=self.model.evaluate_proposal(self.x_data,theta)\n",
    "  #  iniit eta - it is a gaussian random walk in log space of tau^2\n",
    "  eta=np.log(np.var(y_pred[0,]-self.y_data))\n",
    "  tausq_proposal=np.exp(eta) # converting back to tau^2 space\n",
    "\n",
    "  #  finding the prior \n",
    "  prior_val=self.prior(self.sigma_sqr,self.nu_1,self.nu_2,theta,tausq_proposal)\n",
    "  #  finding the likelihood given the data and the model parameters\n",
    "  [likelihood,y_pred[0,],y_sim[0,],rmse[0]]=self.likelihood(theta,tausq_proposal)\n",
    "\n",
    "  n_accept=0 # init we are not accepting  later it changes with time\n",
    "  for i in range(1,self.n_samples):\n",
    "    # sample a new random  tehta and tau using gaussian random walk\n",
    "    theta_proposal=theta+np.random.randn(0,self.theta,self.theta_size)\n",
    "    eta_proposal=eta+np.random.randn(0,self.eta_size,1) # sampling of unknown tau^2 in log space\n",
    "    tausq_proposal=np.exp(eta_proposal)\n",
    "    #  finding the prior for the proposal\n",
    "    prior_proposal=self.prior(self.sigma_sqr,self.nu_1,self.nu_2,theta_proposal,tausq_proposal)\n",
    "    #  finding the likelihood given the data and the model parameters\n",
    "    [likelihood_proposal,y_pred[i,],y_sim[i,],rmse[i]]=self.likelihood(theta_proposal,tausq_proposal)\n",
    "    # finding the test likelihood\n",
    "    [_, y_test_pred[i,], y_sim_test[i,], rmse_test[i]] = self.likelihood(theta_proposal, tausq_proposal, test=True)\n",
    "\n",
    "    #  finding the acceptance ratio\n",
    "    diff_likelihood=likelihood_proposal-likelihood\n",
    "    diff_prior=prior_proposal-prior_val\n",
    "    metropolsih_ratio=min(1,np.exp(diff_likelihood+diff_prior))\n",
    "    #  accept or reject the proposal\n",
    "    # making a general random uniform distribution\n",
    "    u=np.random.rand(0,1)\n",
    "    if u<metropolsih_ratio:\n",
    "      #  accept the proposal\n",
    "      theta=theta_proposal\n",
    "      eta=eta_proposal\n",
    "      prior_val=prior_proposal\n",
    "      likelihood=likelihood_proposal\n",
    "      n_accept+=1\n",
    "      # store the values\n",
    "      post_theta[i,]=theta\n",
    "      post_tau[i,]=tausq_proposal\n",
    "      post_eta[i,]=eta\n",
    "    else:\n",
    "      #  reject the proposal\n",
    "      post_theta[i,]=post_theta[i-1,]\n",
    "      post_tau[i,]=post_tau[i-1,]\n",
    "      post_eta[i,]=post_eta[i-1,]\n",
    "  #  checking the acceptance rate\n",
    "  acceptance_rate=(n_accept/self.n_samples)*100\n",
    "  print(f'Acceptance rate: {acceptance_rate:.2f}%')\n",
    "  # storing the posterior predictions for future use in a dataFrame and returning the results\n",
    "  self.post_theta=post_theta[self.n_burnin:,]\n",
    "  self.post_tau=post_tau[self.n_burnin:,]\n",
    "  self.post_eta=post_eta[self.n_burnin:,]\n",
    "  self.rmse=rmse[self.n_burnin:]\n",
    "  # split theta into w and b\n",
    "  result_dict={\n",
    "    \"w{}\".format(_):self.post_theta[:,_].squeeze() for _ in range(self.theta_size-1)}\n",
    "  result_dict[\"b\"]=self.post_theta[:,-1].squeeze()\n",
    "  result_dict[\"tau\"]=self.post_tau.squeeze()\n",
    "  result_dict[\"eta\"]=self.post_eta.squeeze()\n",
    "  result_dict[\"rmse\"]=self.rmse.squeeze()\n",
    "  \n",
    "  # returning the predictions\n",
    "  pred_dict={}\n",
    "  pred_dict[\"train_pred\"]=y_pred[self.n_burnin:,]\n",
    "  pred_dict[\"train_sim\"]=y_sim[self.n_burnin:,]\n",
    "  pred_dict[\"test_pred\"]=y_test_pred[self.n_burnin:,]\n",
    "  pred_dict[\"test_sim\"]=y_sim_test[self.n_burnin:,]\n",
    "\n",
    "  results_df=pd.DataFrame.from_dict(result_dict)\n",
    "\n",
    "  return results_df, pred_dict\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f34a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCMC:\n",
    "  def __init__(self,n_samples,n_burnin,x_data,y_data,x_test,y_test):\n",
    "    self.n_samples=n_samples  # number of MCMC samples\n",
    "    self.n_burnin=n_burnin # number of burn-in samples\n",
    "    self.x_data = x_data # (N x M)\n",
    "    self.y_data = y_data # (N x 1)\n",
    "    self.x_test = x_test # (Nt x num_features)\n",
    "    self.y_test = y_test # (Nt x 1)\n",
    "    # MCMC sampler hyperparameters - defines the variance term in our Gaussian random walk\n",
    "    self.step_theta=0.01\n",
    "    self.step_eta=0.01 \n",
    "    # model hyperparameters\n",
    "    # considered by looking at distribution of  similar trained  models - i.e distribution of weights and bias\n",
    "    self.sigma_sqr=4\n",
    "    self.nu_1=1\n",
    "    self.nu_2=0.5\n",
    "    #  initialise linear model\n",
    "    self.model=LinearModel()\n",
    "    self.theta_size=x_data.shape[1]+1 # number of features + 1 for bias\n",
    "    # storing the output\n",
    "    self.post_theta=None\n",
    "    self.post_tau=None\n",
    "    self.post_eta=None\n",
    "    self.rmse=None\n",
    "\n",
    "    self.likelihood=MethodType(likelihood, self)\n",
    "    self.prior=MethodType(prior, self)\n",
    "    self.MCMC_sampler=MethodType(MCMC_sampler, self)\n",
    "    self.encode=MethodType(self.model.encode, self.model)\n",
    "\n",
    "    def rmse(self,predictions,targets):\n",
    "      return np.sqrt(((predictions - targets) ** 2).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0b4f6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  This is implementation of linear_model with MCMC sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9e4d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "web_scrapping",
   "language": "python",
   "name": "web_scrapping"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
